{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Flatten, Dense, Input, Dropout\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import model_from_json\nimport numpy as np# Visualize data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize data","metadata":{}},{"cell_type":"code","source":"pip install glob2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install imutils","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport glob2\nimport os\nimport matplotlib.pyplot as plt\nfrom imutils import paths","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classNames = ['aug_handwritten','aug_printed']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path = '/kaggle/input/data-train/TrainCompeticion_WITHGroundTruth/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_1 = list(paths.list_images('/kaggle/input/agu-handwritten/aug_handwritten'))\nprint(\"len class 1: \", len(class_1))\nclass_1_labels = ['1']*len(class_1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_2 = list(paths.list_images('/kaggle/input/aug-printed/aug_printed'))\nprint(\"len class 2: \", len(class_2))\nclass_2_labels = ['2']*len(class_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = class_1_labels + class_2_labels \nimage_links = class_1 + class_2\ndata = pd.DataFrame({'labels': labels, 'image_links':image_links})\ndata.groupby(labels).image_links.count().plot.bar()\nplt.title('Number of images in each class in printed')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimages_train, images_val, y_label_train, y_label_val = train_test_split(image_links, labels, random_state=42, stratify = labels)\n\nprint('images_train len: {}, image_test shape: {}'.format(len(images_train), len(images_val)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentated import numpy as np","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.utils import Sequence, to_categorical\nimport cv2\n\nclass DataGenerator(Sequence):\n    'Generates data for Keras'\n    def __init__(self,\n                 all_filenames, \n                 labels, \n                 batch_size, \n                 index2class,\n                 input_dim,\n                 n_channels,\n                 n_classes=2, \n                 normalize=True,\n                 zoom_range=[0.8, 1],\n                 rotation=15,\n                 brightness_range=[0.8, 1],\n                 shuffle=True):\n        \n        self.all_filenames = all_filenames\n        self.labels = labels\n        self.batch_size = batch_size\n        self.index2class = index2class\n        self.input_dim = input_dim\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.normalize = normalize\n        self.zoom_range = zoom_range\n        self.rotation = rotation\n        self.brightness_range = brightness_range\n        self.on_epoch_end()\n\n    def __len__(self):\n       \n        return int(np.floor(len(self.all_filenames) / self.batch_size))\n\n    def __getitem__(self, index):\n        \n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        all_filenames_temp = [self.all_filenames[k] for k in indexes]\n        X, y = self.__data_generation(all_filenames_temp)\n        return X, y\n\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.all_filenames))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, all_filenames_temp):\n        X = np.empty((self.batch_size, *self.input_dim, self.n_channels))\n        y = np.empty((self.batch_size), dtype=int)\n        for i, fn in enumerate(all_filenames_temp):\n            img = cv2.imread(fn)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, self.input_dim)\n            img_reshape = img.reshape(-1, 3)\n            \n            if self.normalize:\n              mean = np.mean(img_reshape, axis=0)\n              std = np.std(img_reshape, axis=0)\n              img = (img-mean)/std\n\n            if self.zoom_range:\n              zoom_scale = 1/np.random.uniform(self.zoom_range[0], self.zoom_range[1])\n              (h, w, c) = img.shape\n              img = cv2.resize(img, (int(h*zoom_scale), int(w*zoom_scale)), interpolation = cv2.INTER_LINEAR)\n              (h_rz, w_rz, c) = img.shape\n              start_w = np.random.randint(0, w_rz-w) if (w_rz-w) > 0 else 0\n              start_h = np.random.randint(0, h_rz-h) if (h_rz-h) > 0 else 0\n              # print(start_w, start_h)\n              img = img[start_h:(start_h+h), start_w:(start_w+w), :].copy()\n            \n            if self.rotation:\n              (h, w, c) = img.shape\n              angle = np.random.uniform(-self.rotation, self.rotation)\n              RotMat = cv2.getRotationMatrix2D(center = (w, h), angle=angle, scale=1)\n              img = cv2.warpAffine(img, RotMat, (w, h))\n\n            if self.brightness_range:\n              scale_bright = np.random.uniform(self.brightness_range[0], self.brightness_range[1])\n              img = img*scale_bright\n            \n            # dataset_task2/data_classify/0/*.jpg\n            label = fn.split(\"/\")[-3]\n            label = self.index2class[label]\n            # print(\"label: \", label)\n    \n            X[i,] = img\n\n            # LÆ°u class\n            y[i] = label\n        # lb = LabelBinarizer()\n        # y = lb.fit_transform(y)\n        return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_labels = {\n    'aug_handwritten': 0,\n    'aug_printed': 1\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = DataGenerator(\n    all_filenames = images_train,\n    labels = y_label_train,\n    batch_size = 16,\n    index2class = dict_labels,\n    input_dim = (224, 224),\n    n_channels = 3,\n    n_classes = 2,\n    normalize = False,\n    zoom_range = [0.5, 1],\n    rotation = False,\n    brightness_range=[0.8, 1],\n    shuffle = True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator = DataGenerator(\n    all_filenames = images_val,\n    labels = y_label_val,\n    batch_size = 16,\n    index2class = dict_labels,\n    input_dim = (224, 224),\n    n_channels = 3,\n    n_classes = 2,\n    normalize = False,\n    zoom_range = [0.5, 1],\n    rotation = False,\n    brightness_range =[0.8, 1],\n    shuffle = False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check augment","metadata":{}},{"cell_type":"code","source":"check_aug=['/kaggle/input/agu-handwritten/aug_handwritten/Arabic/image_0_1000.png']*32\n\ncheck_generator = DataGenerator(\n    all_filenames = images_val,\n    labels = y_label_val,\n    batch_size = 20,\n    index2class = dict_labels,\n    input_dim = (224, 224),\n    n_channels = 3,\n    n_classes = 2,\n    normalize = False,\n    zoom_range = [0.5, 1],\n    rotation = 15,\n    brightness_range = [0.5, 1.5],\n    shuffle = False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_batch, y_batch = check_generator.__getitem__(0)\n\nprint(X_batch.shape)\nprint(y_batch.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfg, ax = plt.subplots(4, 5, figsize=(20, 16))\nfg.suptitle('Augumentation Images')\n\nfor i in np.arange(4):\n  for j in np.arange(5):\n    ax[i, j].imshow(X_batch[i + j + j*i]/255.0)\n    ax[i, j].set_xlabel('Image '+str(i+j+j*i))\n    ax[i, j].axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine-tune","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB4, EfficientNetB7\nfrom keras.layers import Activation,Flatten, Dense, Input, Dropout, AveragePooling2D","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(baseModel, number_class, lr=1e-4, decay=1e-4/25):\n\n    headModel = baseModel.output\n    headModel = AveragePooling2D(pool_size=(3, 3))(headModel)\n    headModel = Flatten(name=\"flatten\")(headModel)\n    headModel = Dense(1024, activation=\"relu\")(headModel)\n    headModel = Dropout(0.5)(headModel)\n    headModel = Dense(number_class, activation=\"softmax\")(headModel)\n    model = Model(inputs=baseModel.input, outputs=headModel)\n\n    for layer in baseModel.layers:\n      layer.trainable = False\n    \n    # compile model\n    optimizer = Adam(lr=lr, decay = decay)\n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,metrics=\"accuracy\")\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseModel = EfficientNetB7(weights=\"imagenet\", include_top=False,\n\tinput_tensor=Input(shape=(224, 224, 3)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model(baseModel, 2, lr=1e-4, decay=1e-4/25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train step 1","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_generator,\n                   validation_data= val_generator, \n                   epochs=5) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train step 2","metadata":{}},{"cell_type":"code","source":"from keras.optimizers import SGD","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in baseModel.layers[20:]:\n    layer.trainable = True\n\n#recompile the model\nprint(\"[INFO] re-compiling model...\")\nopt = SGD(lr=0.001)\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,\n            metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/checkpoint","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_checkpointer = [\n                EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n                ModelCheckpoint(filepath=\"/kaggle/working/checkpoint/effb7_10epoch.h5\", verbose=2, save_weights_only=True)\n                ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator,\n                  #  steps_per_epoch=20, \n                   validation_data= val_generator, \n                  #  validation_steps=10, \n                   epochs=5,\n                   callbacks=my_checkpointer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/model/model_hand_printed.h5')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(r'model/model_hand_printed.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}